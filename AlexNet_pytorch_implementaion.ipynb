{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:01.186847Z","iopub.execute_input":"2025-02-13T12:41:01.187172Z","iopub.status.idle":"2025-02-13T12:41:01.483378Z","shell.execute_reply.started":"2025-02-13T12:41:01.187119Z","shell.execute_reply":"2025-02-13T12:41:01.482514Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:01.484379Z","iopub.execute_input":"2025-02-13T12:41:01.484759Z","iopub.status.idle":"2025-02-13T12:41:04.816260Z","shell.execute_reply.started":"2025-02-13T12:41:01.484730Z","shell.execute_reply":"2025-02-13T12:41:04.815383Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self, num_classes = 10):\n        super(AlexNet, self).__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size = 11, stride = 4, padding = 2),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size = 3, stride = 2),\n\n            nn.Conv2d(64, 192, kernel_size = 5, padding = 2),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size = 3, stride = 2),\n\n            nn.Conv2d(192, 384, kernel_size = 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(384, 256, kernel_size = 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size = 3, stride = 2),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace = True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace = True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:04.817693Z","iopub.execute_input":"2025-02-13T12:41:04.818061Z","iopub.status.idle":"2025-02-13T12:41:04.824446Z","shell.execute_reply.started":"2025-02-13T12:41:04.818039Z","shell.execute_reply":"2025-02-13T12:41:04.823730Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:04.825689Z","iopub.execute_input":"2025-02-13T12:41:04.825955Z","iopub.status.idle":"2025-02-13T12:41:07.116225Z","shell.execute_reply.started":"2025-02-13T12:41:04.825928Z","shell.execute_reply":"2025-02-13T12:41:07.115564Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((227, 227)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = CIFAR10(root = './data', train = True,transform = transform, download = True)\ntest_dataset = CIFAR10(root = './data', train = False, transform = transform, download = True)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\ntest_loader = DataLoader(test_dataset, batch_size = 54, shuffle = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:07.116902Z","iopub.execute_input":"2025-02-13T12:41:07.117222Z","iopub.status.idle":"2025-02-13T12:41:16.589262Z","shell.execute_reply.started":"2025-02-13T12:41:07.117203Z","shell.execute_reply":"2025-02-13T12:41:16.588563Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:05<00:00, 29.7MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:16.590124Z","iopub.execute_input":"2025-02-13T12:41:16.590390Z","iopub.status.idle":"2025-02-13T12:41:16.594036Z","shell.execute_reply.started":"2025-02-13T12:41:16.590368Z","shell.execute_reply":"2025-02-13T12:41:16.593227Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = AlexNet(num_classes = 10).to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 0.0005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:41:16.594889Z","iopub.execute_input":"2025-02-13T12:41:16.595123Z","iopub.status.idle":"2025-02-13T12:41:17.401970Z","shell.execute_reply.started":"2025-02-13T12:41:16.595093Z","shell.execute_reply":"2025-02-13T12:41:17.401336Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T12:51:54.142574Z","iopub.execute_input":"2025-02-13T12:51:54.142863Z","iopub.status.idle":"2025-02-13T13:08:52.968585Z","shell.execute_reply.started":"2025-02-13T12:51:54.142843Z","shell.execute_reply":"2025-02-13T13:08:52.967802Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.4987\nEpoch [2/10], Loss: 0.4446\nEpoch [3/10], Loss: 0.3889\nEpoch [4/10], Loss: 0.3458\nEpoch [5/10], Loss: 0.3142\nEpoch [6/10], Loss: 0.2911\nEpoch [7/10], Loss: 0.2590\nEpoch [8/10], Loss: 0.2525\nEpoch [9/10], Loss: 0.2262\nEpoch [10/10], Loss: 0.2128\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.eval()\n\ncorrect, total = 0, 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to('cuda'), labels.to('cuda')\n        outputs = model(images)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T13:08:57.236641Z","iopub.execute_input":"2025-02-13T13:08:57.236946Z","iopub.status.idle":"2025-02-13T13:09:19.414236Z","shell.execute_reply.started":"2025-02-13T13:08:57.236921Z","shell.execute_reply":"2025-02-13T13:09:19.413438Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 82.50%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}